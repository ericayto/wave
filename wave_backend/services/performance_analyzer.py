"""
Advanced Performance Analytics
Sophisticated performance metrics with ML insights, regime detection, and deep analytics.
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import logging
import numpy as np
import pandas as pd
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

from ..config.settings import get_settings
from ..services.event_bus import EventBus

logger = logging.getLogger(__name__)

@dataclass
class AdvancedMetrics:
    """Advanced performance metrics."""
    # Risk-adjusted returns
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float
    omega_ratio: float
    
    # Drawdown analysis
    max_drawdown: float
    max_drawdown_duration: int
    avg_drawdown: float
    drawdown_recovery_time: float
    
    # Win/Loss analysis
    win_rate: float
    profit_factor: float
    avg_win: float
    avg_loss: float
    win_loss_ratio: float
    expectancy: float
    
    # Streak analysis
    max_win_streak: int
    max_loss_streak: int
    avg_win_streak: float
    avg_loss_streak: float
    
    # Risk metrics
    value_at_risk_95: float
    conditional_var_95: float
    tail_ratio: float
    skewness: float
    kurtosis: float
    
    # Time-based metrics
    annual_return: float
    annual_volatility: float
    monthly_returns_std: float
    best_month: float
    worst_month: float
    
    # Market correlation
    market_correlation: float
    beta: float
    alpha: float
    information_ratio: float
    treynor_ratio: float

@dataclass 
class RegimeAnalysis:
    """Market regime analysis."""
    current_regime: str  # 'trending', 'mean_reverting', 'high_volatility', 'low_volatility'
    regime_probability: float
    regime_duration: int  # days in current regime
    regime_history: List[Dict]  # Historical regime transitions
    regime_performance: Dict[str, Dict]  # Performance by regime
    
@dataclass
class PerformanceInsight:
    """Performance insight generated by analysis."""
    type: str  # 'strength', 'weakness', 'opportunity', 'threat'
    category: str  # 'risk', 'return', 'timing', 'diversification'
    message: str
    confidence: float
    supporting_data: Dict[str, Any]
    actionable: bool
    suggested_action: Optional[str] = None

class PerformanceAnalyzer:
    """Advanced performance analytics with ML insights."""
    
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        self.settings = get_settings()
        
        # Cache for performance calculations
        self.performance_cache = {}
        self.cache_ttl = 300  # 5 minutes
        
        # ML models for regime detection
        self.regime_model = None
        self.scaler = StandardScaler()
        
        # Historical data storage
        self.price_history = {}
        self.returns_history = {}
        self.regime_history = []
        
    async def calculate_advanced_metrics(self, 
                                       strategy_id: str, 
                                       timeframe: str = "1d") -> AdvancedMetrics:
        """Calculate sophisticated performance metrics."""
        
        cache_key = f"{strategy_id}_{timeframe}_metrics"
        if self._is_cached(cache_key):
            return self.performance_cache[cache_key]['data']
        
        # Get strategy performance data
        performance_data = await self._get_strategy_performance(strategy_id, timeframe)
        
        if not performance_data or len(performance_data) < 10:
            logger.warning(f"Insufficient data for strategy {strategy_id}")
            return self._default_metrics()
        
        returns = np.array(performance_data['returns'])
        equity_curve = np.array(performance_data['equity_curve'])
        
        # Calculate all advanced metrics
        metrics = await self._calculate_all_metrics(returns, equity_curve)
        
        # Cache results
        self._cache_result(cache_key, metrics)
        
        return metrics
    
    async def _calculate_all_metrics(self, returns: np.ndarray, equity_curve: np.ndarray) -> AdvancedMetrics:
        """Calculate all advanced metrics."""
        
        # Risk-adjusted returns
        risk_free_rate = 0.02 / 252  # 2% annual risk-free rate, daily
        excess_returns = returns - risk_free_rate
        
        sharpe_ratio = self._calculate_sharpe(excess_returns)
        sortino_ratio = self._calculate_sortino(excess_returns)
        calmar_ratio = self._calculate_calmar(returns, equity_curve)
        omega_ratio = self._calculate_omega(excess_returns)
        
        # Drawdown analysis
        drawdowns = self._calculate_drawdowns(equity_curve)
        max_drawdown = abs(min(drawdowns))
        max_dd_duration = self._max_drawdown_duration(drawdowns)
        avg_drawdown = np.mean([dd for dd in drawdowns if dd < 0])
        recovery_time = self._avg_recovery_time(drawdowns)
        
        # Win/Loss analysis
        wins = returns[returns > 0]
        losses = returns[returns < 0]
        
        win_rate = len(wins) / len(returns) if len(returns) > 0 else 0
        avg_win = np.mean(wins) if len(wins) > 0 else 0
        avg_loss = np.mean(losses) if len(losses) > 0 else 0
        win_loss_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else 0
        profit_factor = sum(wins) / abs(sum(losses)) if sum(losses) != 0 else 0
        expectancy = (win_rate * avg_win) - ((1 - win_rate) * abs(avg_loss))
        
        # Streak analysis
        streaks = self._calculate_streaks(returns)
        
        # Risk metrics
        var_95 = np.percentile(returns, 5)
        cvar_95 = np.mean(returns[returns <= var_95]) if any(returns <= var_95) else var_95
        tail_ratio = abs(var_95 / cvar_95) if cvar_95 != 0 else 1
        
        skewness = stats.skew(returns)
        kurtosis = stats.kurtosis(returns)
        
        # Time-based metrics
        annual_return = (equity_curve[-1] / equity_curve[0]) ** (252 / len(returns)) - 1
        annual_volatility = np.std(returns) * np.sqrt(252)
        monthly_returns = self._get_monthly_returns(returns)
        monthly_std = np.std(monthly_returns) if len(monthly_returns) > 1 else 0
        
        # Market correlation (mock for now - would use market index)
        market_returns = np.random.normal(0.0005, 0.02, len(returns))  # Mock market
        correlation = np.corrcoef(returns, market_returns)[0, 1]
        beta = np.cov(returns, market_returns)[0, 1] / np.var(market_returns)
        alpha = annual_return - (risk_free_rate * 252 + beta * 0.08)  # 8% market return
        
        return AdvancedMetrics(
            sharpe_ratio=sharpe_ratio,
            sortino_ratio=sortino_ratio,
            calmar_ratio=calmar_ratio,
            omega_ratio=omega_ratio,
            max_drawdown=max_drawdown,
            max_drawdown_duration=max_dd_duration,
            avg_drawdown=avg_drawdown,
            drawdown_recovery_time=recovery_time,
            win_rate=win_rate,
            profit_factor=profit_factor,
            avg_win=avg_win,
            avg_loss=avg_loss,
            win_loss_ratio=win_loss_ratio,
            expectancy=expectancy,
            max_win_streak=streaks['max_win_streak'],
            max_loss_streak=streaks['max_loss_streak'],
            avg_win_streak=streaks['avg_win_streak'],
            avg_loss_streak=streaks['avg_loss_streak'],
            value_at_risk_95=var_95,
            conditional_var_95=cvar_95,
            tail_ratio=tail_ratio,
            skewness=skewness,
            kurtosis=kurtosis,
            annual_return=annual_return,
            annual_volatility=annual_volatility,
            monthly_returns_std=monthly_std,
            best_month=max(monthly_returns) if monthly_returns else 0,
            worst_month=min(monthly_returns) if monthly_returns else 0,
            market_correlation=correlation,
            beta=beta,
            alpha=alpha,
            information_ratio=alpha / np.std(excess_returns) if np.std(excess_returns) != 0 else 0,
            treynor_ratio=annual_return / beta if beta != 0 else 0
        )
    
    def _calculate_sharpe(self, excess_returns: np.ndarray) -> float:
        """Calculate Sharpe ratio."""
        if len(excess_returns) == 0 or np.std(excess_returns) == 0:
            return 0.0
        return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)
    
    def _calculate_sortino(self, excess_returns: np.ndarray) -> float:
        """Calculate Sortino ratio."""
        if len(excess_returns) == 0:
            return 0.0
        downside_returns = excess_returns[excess_returns < 0]
        if len(downside_returns) == 0:
            return float('inf')
        downside_std = np.std(downside_returns)
        if downside_std == 0:
            return 0.0
        return np.mean(excess_returns) / downside_std * np.sqrt(252)
    
    def _calculate_calmar(self, returns: np.ndarray, equity_curve: np.ndarray) -> float:
        """Calculate Calmar ratio."""
        if len(returns) == 0:
            return 0.0
        annual_return = (equity_curve[-1] / equity_curve[0]) ** (252 / len(returns)) - 1
        drawdowns = self._calculate_drawdowns(equity_curve)
        max_drawdown = abs(min(drawdowns))
        if max_drawdown == 0:
            return float('inf')
        return annual_return / max_drawdown
    
    def _calculate_omega(self, excess_returns: np.ndarray, threshold: float = 0.0) -> float:
        """Calculate Omega ratio."""
        if len(excess_returns) == 0:
            return 1.0
        gains = excess_returns[excess_returns > threshold]
        losses = excess_returns[excess_returns <= threshold]
        
        if len(losses) == 0:
            return float('inf')
        if len(gains) == 0:
            return 0.0
        
        return sum(gains - threshold) / abs(sum(losses - threshold))
    
    def _calculate_drawdowns(self, equity_curve: np.ndarray) -> np.ndarray:
        """Calculate drawdown series."""
        peak = np.maximum.accumulate(equity_curve)
        return (equity_curve - peak) / peak
    
    def _max_drawdown_duration(self, drawdowns: np.ndarray) -> int:
        """Calculate maximum drawdown duration."""
        is_drawdown = drawdowns < 0
        if not any(is_drawdown):
            return 0
        
        # Find drawdown periods
        drawdown_periods = []
        start = None
        
        for i, is_dd in enumerate(is_drawdown):
            if is_dd and start is None:
                start = i
            elif not is_dd and start is not None:
                drawdown_periods.append(i - start)
                start = None
        
        if start is not None:  # Ongoing drawdown
            drawdown_periods.append(len(drawdowns) - start)
        
        return max(drawdown_periods) if drawdown_periods else 0
    
    def _avg_recovery_time(self, drawdowns: np.ndarray) -> float:
        """Calculate average recovery time."""
        recovery_times = []
        in_drawdown = False
        drawdown_start = 0
        
        for i, dd in enumerate(drawdowns):
            if dd < 0 and not in_drawdown:
                in_drawdown = True
                drawdown_start = i
            elif dd >= 0 and in_drawdown:
                recovery_times.append(i - drawdown_start)
                in_drawdown = False
        
        return np.mean(recovery_times) if recovery_times else 0
    
    def _calculate_streaks(self, returns: np.ndarray) -> Dict[str, float]:
        """Calculate win/loss streaks."""
        if len(returns) == 0:
            return {
                'max_win_streak': 0,
                'max_loss_streak': 0,
                'avg_win_streak': 0,
                'avg_loss_streak': 0
            }
        
        win_streaks = []
        loss_streaks = []
        current_win_streak = 0
        current_loss_streak = 0
        
        for ret in returns:
            if ret > 0:
                if current_loss_streak > 0:
                    loss_streaks.append(current_loss_streak)
                    current_loss_streak = 0
                current_win_streak += 1
            elif ret < 0:
                if current_win_streak > 0:
                    win_streaks.append(current_win_streak)
                    current_win_streak = 0
                current_loss_streak += 1
            # ret == 0 breaks both streaks
            else:
                if current_win_streak > 0:
                    win_streaks.append(current_win_streak)
                    current_win_streak = 0
                if current_loss_streak > 0:
                    loss_streaks.append(current_loss_streak)
                    current_loss_streak = 0
        
        # Add final streaks
        if current_win_streak > 0:
            win_streaks.append(current_win_streak)
        if current_loss_streak > 0:
            loss_streaks.append(current_loss_streak)
        
        return {
            'max_win_streak': max(win_streaks) if win_streaks else 0,
            'max_loss_streak': max(loss_streaks) if loss_streaks else 0,
            'avg_win_streak': np.mean(win_streaks) if win_streaks else 0,
            'avg_loss_streak': np.mean(loss_streaks) if loss_streaks else 0
        }
    
    def _get_monthly_returns(self, daily_returns: np.ndarray) -> List[float]:
        """Convert daily returns to monthly returns."""
        if len(daily_returns) < 20:  # Less than a month
            return []
        
        # Simple approximation: group every 21 trading days
        monthly_returns = []
        for i in range(0, len(daily_returns), 21):
            month_returns = daily_returns[i:i+21]
            if len(month_returns) >= 10:  # At least half a month
                monthly_return = np.prod(1 + month_returns) - 1
                monthly_returns.append(monthly_return)
        
        return monthly_returns
    
    async def detect_performance_regimes(self, strategy_id: str) -> RegimeAnalysis:
        """Detect different market regimes and performance patterns."""
        
        # Get extended performance data
        performance_data = await self._get_strategy_performance(strategy_id, "1d", days=365)
        
        if not performance_data or len(performance_data) < 60:
            return self._default_regime_analysis()
        
        # Feature engineering for regime detection
        features = self._extract_regime_features(performance_data)
        
        # Detect regimes using clustering
        if self.regime_model is None:
            self._train_regime_model(features)
        
        current_regime = self._classify_current_regime(features[-30:])  # Last 30 days
        regime_prob = self._calculate_regime_probability(features[-30:])
        
        # Calculate regime duration
        regime_duration = self._calculate_current_regime_duration()
        
        # Analyze performance by regime
        regime_performance = await self._analyze_regime_performance(strategy_id, performance_data)
        
        return RegimeAnalysis(
            current_regime=current_regime,
            regime_probability=regime_prob,
            regime_duration=regime_duration,
            regime_history=self.regime_history[-30:],  # Last 30 regime changes
            regime_performance=regime_performance
        )
    
    def _extract_regime_features(self, performance_data: Dict) -> np.ndarray:
        """Extract features for regime detection."""
        returns = np.array(performance_data['returns'])
        prices = np.array(performance_data['prices'])
        
        # Rolling statistics
        window = 20
        features = []
        
        for i in range(window, len(returns)):
            window_returns = returns[i-window:i]
            window_prices = prices[i-window:i]
            
            # Volatility features
            volatility = np.std(window_returns)
            
            # Trend features  
            trend = np.polyfit(range(window), window_prices, 1)[0]
            
            # Mean reversion features
            price_mean = np.mean(window_prices)
            mean_reversion = abs(prices[i] - price_mean) / price_mean
            
            # Momentum features
            momentum = sum(window_returns[-5:])  # 5-day momentum
            
            features.append([volatility, trend, mean_reversion, momentum])
        
        return np.array(features)
    
    def _train_regime_model(self, features: np.ndarray):
        """Train regime detection model."""
        # Normalize features
        features_scaled = self.scaler.fit_transform(features)
        
        # Use K-means clustering to identify regimes
        self.regime_model = KMeans(n_clusters=4, random_state=42, n_init=10)
        self.regime_model.fit(features_scaled)
        
        # Map clusters to regime names
        self.regime_labels = {
            0: 'low_volatility',
            1: 'high_volatility', 
            2: 'trending',
            3: 'mean_reverting'
        }
    
    def _classify_current_regime(self, recent_features: np.ndarray) -> str:
        """Classify current market regime."""
        if self.regime_model is None or len(recent_features) == 0:
            return 'unknown'
        
        features_scaled = self.scaler.transform(recent_features)
        predictions = self.regime_model.predict(features_scaled)
        
        # Most common regime in recent period
        regime_id = stats.mode(predictions, keepdims=True)[0][0]
        return self.regime_labels.get(regime_id, 'unknown')
    
    def _calculate_regime_probability(self, recent_features: np.ndarray) -> float:
        """Calculate confidence in current regime classification."""
        if self.regime_model is None or len(recent_features) == 0:
            return 0.0
        
        features_scaled = self.scaler.transform(recent_features)
        
        # Calculate distance to cluster centers
        distances = self.regime_model.transform(features_scaled)
        min_distances = np.min(distances, axis=1)
        
        # Convert to probability (closer = higher probability)
        avg_distance = np.mean(min_distances)
        probability = max(0.0, 1.0 - (avg_distance / np.max(distances)))
        
        return probability
    
    def _calculate_current_regime_duration(self) -> int:
        """Calculate days in current regime."""
        if not self.regime_history:
            return 0
        
        current_date = datetime.utcnow().date()
        for i, regime_change in enumerate(reversed(self.regime_history)):
            change_date = datetime.fromisoformat(regime_change['date']).date()
            if change_date != current_date:
                return i
        
        return len(self.regime_history)
    
    async def _analyze_regime_performance(self, strategy_id: str, performance_data: Dict) -> Dict[str, Dict]:
        """Analyze performance by regime."""
        # Mock implementation - would be fully implemented with real regime data
        regimes = ['trending', 'mean_reverting', 'high_volatility', 'low_volatility']
        performance_by_regime = {}
        
        for regime in regimes:
            # Mock performance statistics per regime
            performance_by_regime[regime] = {
                'total_return': np.random.uniform(-0.1, 0.3),
                'sharpe_ratio': np.random.uniform(0.5, 2.5),
                'win_rate': np.random.uniform(0.4, 0.7),
                'avg_trade_duration': np.random.uniform(2, 10),
                'max_drawdown': np.random.uniform(0.02, 0.15),
                'trade_count': np.random.randint(10, 100),
                'profit_factor': np.random.uniform(0.8, 2.2)
            }
        
        return performance_by_regime
    
    async def generate_performance_insights(self, strategy_id: str) -> List[PerformanceInsight]:
        """Use ML to generate actionable performance insights."""
        
        # Get comprehensive performance data
        metrics = await self.calculate_advanced_metrics(strategy_id)
        regime_analysis = await self.detect_performance_regimes(strategy_id)
        
        insights = []
        
        # Risk analysis insights
        if metrics.sharpe_ratio < 1.0:
            insights.append(PerformanceInsight(
                type='weakness',
                category='risk',
                message=f"Low risk-adjusted returns (Sharpe: {metrics.sharpe_ratio:.2f})",
                confidence=0.85,
                supporting_data={'sharpe_ratio': metrics.sharpe_ratio},
                actionable=True,
                suggested_action="Consider reducing position size or improving entry/exit rules"
            ))
        
        # Drawdown analysis
        if metrics.max_drawdown > 0.15:
            insights.append(PerformanceInsight(
                type='threat',
                category='risk',
                message=f"High maximum drawdown ({metrics.max_drawdown:.1%})",
                confidence=0.9,
                supporting_data={'max_drawdown': metrics.max_drawdown},
                actionable=True,
                suggested_action="Implement stricter stop-loss rules or position sizing"
            ))
        
        # Win rate analysis
        if metrics.win_rate < 0.5 and metrics.win_loss_ratio > 2.0:
            insights.append(PerformanceInsight(
                type='strength',
                category='return',
                message="Strong asymmetric return profile (high win/loss ratio)",
                confidence=0.8,
                supporting_data={
                    'win_rate': metrics.win_rate,
                    'win_loss_ratio': metrics.win_loss_ratio
                },
                actionable=False
            ))
        
        # Regime analysis insights
        if regime_analysis.current_regime in regime_analysis.regime_performance:
            regime_perf = regime_analysis.regime_performance[regime_analysis.current_regime]
            if regime_perf['sharpe_ratio'] < 1.0:
                insights.append(PerformanceInsight(
                    type='opportunity',
                    category='timing',
                    message=f"Underperforming in {regime_analysis.current_regime} market regime",
                    confidence=regime_analysis.regime_probability,
                    supporting_data={
                        'current_regime': regime_analysis.current_regime,
                        'regime_sharpe': regime_perf['sharpe_ratio']
                    },
                    actionable=True,
                    suggested_action=f"Consider regime-specific parameters or pause trading in {regime_analysis.current_regime} conditions"
                ))
        
        # Volatility insights
        if metrics.skewness < -1.0:
            insights.append(PerformanceInsight(
                type='threat',
                category='risk',
                message="Negative skew indicates tail risk exposure",
                confidence=0.75,
                supporting_data={'skewness': metrics.skewness},
                actionable=True,
                suggested_action="Consider tail risk hedging or reduce position size during high volatility"
            ))
        
        # Sort insights by confidence and actionability
        insights.sort(key=lambda x: (x.actionable, x.confidence), reverse=True)
        
        return insights[:10]  # Return top 10 insights
    
    async def _get_strategy_performance(self, strategy_id: str, timeframe: str = "1d", days: int = 90) -> Dict:
        """Get strategy performance data."""
        # Mock implementation - would fetch from database
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=days)
        
        # Generate mock performance data
        n_days = (end_date - start_date).days
        dates = pd.date_range(start_date, end_date, freq='D')[:n_days]
        
        # Realistic random walk with drift
        np.random.seed(hash(strategy_id) % 2**32)  # Deterministic for each strategy
        daily_returns = np.random.normal(0.0008, 0.02, n_days)  # ~20% annual vol
        prices = 100 * np.cumprod(1 + daily_returns)
        equity_curve = 10000 * np.cumprod(1 + daily_returns)  # Starting with $10k
        
        return {
            'dates': [d.isoformat() for d in dates],
            'returns': daily_returns.tolist(),
            'prices': prices.tolist(),
            'equity_curve': equity_curve.tolist()
        }
    
    def _default_metrics(self) -> AdvancedMetrics:
        """Return default metrics when insufficient data."""
        return AdvancedMetrics(
            sharpe_ratio=0.0,
            sortino_ratio=0.0,
            calmar_ratio=0.0,
            omega_ratio=1.0,
            max_drawdown=0.0,
            max_drawdown_duration=0,
            avg_drawdown=0.0,
            drawdown_recovery_time=0.0,
            win_rate=0.0,
            profit_factor=1.0,
            avg_win=0.0,
            avg_loss=0.0,
            win_loss_ratio=0.0,
            expectancy=0.0,
            max_win_streak=0,
            max_loss_streak=0,
            avg_win_streak=0.0,
            avg_loss_streak=0.0,
            value_at_risk_95=0.0,
            conditional_var_95=0.0,
            tail_ratio=1.0,
            skewness=0.0,
            kurtosis=0.0,
            annual_return=0.0,
            annual_volatility=0.0,
            monthly_returns_std=0.0,
            best_month=0.0,
            worst_month=0.0,
            market_correlation=0.0,
            beta=1.0,
            alpha=0.0,
            information_ratio=0.0,
            treynor_ratio=0.0
        )
    
    def _default_regime_analysis(self) -> RegimeAnalysis:
        """Return default regime analysis when insufficient data."""
        return RegimeAnalysis(
            current_regime='unknown',
            regime_probability=0.0,
            regime_duration=0,
            regime_history=[],
            regime_performance={}
        )
    
    def _is_cached(self, cache_key: str) -> bool:
        """Check if result is cached and still valid."""
        if cache_key not in self.performance_cache:
            return False
        
        cache_entry = self.performance_cache[cache_key]
        return (datetime.utcnow() - cache_entry['timestamp']).seconds < self.cache_ttl
    
    def _cache_result(self, cache_key: str, data: Any):
        """Cache analysis result."""
        self.performance_cache[cache_key] = {
            'data': data,
            'timestamp': datetime.utcnow()
        }
    
    def get_performance_summary(self, strategy_id: str) -> Dict[str, Any]:
        """Get performance summary for API responses."""
        # This would return cached or quickly calculated summary
        return {
            'strategy_id': strategy_id,
            'last_updated': datetime.utcnow().isoformat(),
            'status': 'active',
            'key_metrics': {
                'sharpe_ratio': 1.2,
                'max_drawdown': 0.08,
                'win_rate': 0.58,
                'annual_return': 0.15
            }
        }